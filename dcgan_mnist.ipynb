{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Reshape, Dense, Dropout, Flatten, Convolution2D, UpSampling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "\n",
    "randomDim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train [:, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=randomDim, kernel_initializer='normal'))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Reshape((7,7,128)))\n",
    "generator.add(UpSampling2D(size=(2, 2)))\n",
    "generator.add(Convolution2D(64, (5, 5), padding='same'))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(UpSampling2D(size=(2,2)))\n",
    "generator.add(Convolution2D(1, (5, 5), padding='same', activation='tanh'))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator \n",
    "discriminator = Sequential()\n",
    "discriminator.add(Convolution2D(64, (5,5), padding='same', input_shape=(28,28,1), strides= (2,2), kernel_initializer='normal'))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Convolution2D(128, (5,5), padding='same', strides=(2,2)))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Network\n",
    "discriminator.trainable = False\n",
    "ganInput = Input(shape=(randomDim,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = Model(inputs = ganInput, outputs = ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dLosses = []\n",
    "gLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(epoch):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(dLosses, label=\"Discriminative loss\")\n",
    "    plt.plot(gLosses, label=\"Generative loss\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('images/dcgan_loss_epoch_%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGeneratedImages(epoch, example=100, dim=(10,10), figsize=(10,10)):\n",
    "    noise = np.random.normal(0, 1, size=[example, randomDim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i,0], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/dcgan_generated_images_epoch_%d.png' %epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = X_train.shape[0]//batchSize\n",
    "    print (\"Epochs : \", epochs)\n",
    "    print (\"BatchSize : \", batchSize)\n",
    "    print (\"Batches per epoch : \", batchCount)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        print (\"-\"*20, \"Epoch : %d\" % e , \"-\"*20)\n",
    "        for _ in tqdm(range(batchCount)):\n",
    "            \n",
    "            noise = np.random.normal(0, 1 , size=[batchSize, randomDim])\n",
    "            imageBatch = X_train[np.random.randint(0,X_train.shape[0] , size=batchSize)]\n",
    "            \n",
    "            generatedImages = generator.predict(noise)\n",
    "            X = np.concatenate([imageBatch, generatedImages])\n",
    "            \n",
    "            #labels\n",
    "            yDis = np.zeros(2*batchSize)\n",
    "            yDis[:batchSize] = 0.9\n",
    "            \n",
    "            #train discriminator\n",
    "            discriminator.trainable = True\n",
    "            dloss = discriminator.train_on_batch(X, yDis)\n",
    "            \n",
    "            #train generator \n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "        \n",
    "        dLosses.append(dloss)\n",
    "        gLosses.append(gloss)\n",
    "        \n",
    "        if e == 1 or e % 5 == 0:\n",
    "            plotGeneratedImages(e)\n",
    "    \n",
    "    plotLoss(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epochs : ', 50)\n",
      "('BatchSize : ', 128)\n",
      "('Batches per epoch : ', 468)\n",
      "('--------------------', 'Epoch : 1', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:36<00:00,  1.98it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 2', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:52<00:00,  2.01it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 3', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:08<00:00,  2.03it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 4', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:05<00:00,  1.68it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 5', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:12<00:00,  1.87it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 6', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:12<00:00,  1.79it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 7', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:25<00:00,  1.70it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 8', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:15<00:00,  1.94it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 9', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:20<00:00,  1.88it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 10', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:14<00:00,  1.88it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 11', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [04:11<00:00,  1.94it/s]\n",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('--------------------', 'Epoch : 12', '--------------------')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 390/468 [04:03<00:44,  1.74it/s]"
     ]
    }
   ],
   "source": [
    "train(50,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
